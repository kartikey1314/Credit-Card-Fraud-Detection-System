# -*- coding: utf-8 -*-
"""creditcardmodel2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DP3hPFpHYAxETQtdntH8dqFLXN1wKxkN
"""

import pandas as pd
import numpy as np

df = pd.read_csv("creditcard.csv")
df.head()

from sklearn.preprocessing import StandardScaler

# Standardize 'Amount' and 'Time'
scaler = StandardScaler()
df["scaled_amount"] = scaler.fit_transform(df[["Amount"]])
df["scaled_time"] = scaler.fit_transform(df[["Time"]])

df.drop(["Time", "Amount"], axis=1, inplace=True)

# Reorder columns
scaled_cols = ["scaled_amount", "scaled_time"]
others = [col for col in df.columns if col not in scaled_cols + ["Class"]]
df = df[scaled_cols + others + ["Class"]]

df.head()

df = df.dropna(subset=["Class"])

from sklearn.model_selection import train_test_split


#Define features and target
X = df.drop("Class", axis=1)
y = df["Class"]

# ðŸ“¤ Split dataset (stratified to keep class distribution)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
    roc_auc_score,
    roc_curve
)
lr = LogisticRegression(max_iter=1000, class_weight="balanced")
lr.fit(X_train, y_train)

# Predictions
y_pred_lr = lr.predict(X_test)
y_proba_lr = lr.predict_proba(X_test)[:, 1]

from imblearn.over_sampling import SMOTE

sm = SMOTE(random_state=42)
X_res, y_res = sm.fit_resample(X_train, y_train)

print("Before SMOTE:", np.bincount(y_train))
print("After SMOTE:", np.bincount(y_res))

rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight="balanced")
rf.fit(X_res, y_res)

# Predictions
y_pred_rf = rf.predict(X_test)
y_proba_rf = rf.predict_proba(X_test)[:, 1]

def evaluate_model(name, y_true, y_pred, y_proba):
    print(f"\n Evaluation for: {name}")
    print(" Accuracy:", round(accuracy_score(y_true, y_pred) * 100, 2), "%")
    print("Classification Report:")
    print(classification_report(y_true, y_pred, digits=4))
    print(" Confusion Matrix:")
    print(confusion_matrix(y_true, y_pred))
    print(" ROC AUC Score:", round(roc_auc_score(y_true, y_proba), 4))

evaluate_model("Original Logistic Regression", y_test, y_pred_lr, y_proba_lr)
evaluate_model("Optimized Random Forest (SMOTE)", y_test, y_pred_rf, y_proba_rf)

import matplotlib.pyplot as plt
import seaborn as sns
fpr_lr, tpr_lr, _ = roc_curve(y_test, y_proba_lr)
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_proba_rf)

plt.figure(figsize=(10, 6))
plt.plot(fpr_lr, tpr_lr, label="Logistic Regression (AUC = %.4f)" % roc_auc_score(y_test, y_proba_lr))
plt.plot(fpr_rf, tpr_rf, label="Random Forest + SMOTE (AUC = %.4f)" % roc_auc_score(y_test, y_proba_rf))
plt.plot([0, 1], [0, 1], "k--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve Comparison")
plt.legend()
plt.grid(True)
plt.show()